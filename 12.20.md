# 今日任务

flink部署到yarn

flinkCDC读取mysql然后发送到kafka 最后部署到yarn

# 问题

### 	问题一：

​	有的代码找不到可导入的类，然后自己感觉是pom的问题，然后就更改pom一个个找，最后发现是版本的问题，更改了版本就好了

### 	问题二：

[ERROR] Failed to execute goal org.apache.maven.plugins:maven-resources-plugin:2.6:resources (default-resources) on project realtime-common: Error loading property file 'D:\shixun\FLink-CDC_ToSink-Kafka\realtime-common\src\main\resources\filter\common-config.properties.dev' -> [Help 1]

​	仔细阅读报错发现说是realtime-common\src\main\resources\filter目录下面的common-config.properties.dev文件，但是我发现没有，我就想是不是哪个路径搞错了，然后在pom里面发现了，但是又怕把pom搞坏，就从别的地方复制过来了，问题就解决了

### 	问题三：

Could not transfer artifact sy.x:FLink-CDC_ToSink-Kafka:pom:1.0-SNAPSHOT from/to nexus (http://localhost:8081/repository/maven-public/): transfer failed for http://localhost:8081/repository/maven-public/sy/x/FLink-CDC_ToSink-Kafka/1.0-SNAPSHOT/FLink-CDC_ToSink-Kafka-1.0-SNAPSHOT.pom

​	然后搜了很多东西，都没有搜到解决方案，然后自己就根据报错去找，从报错中说的pom开始去找，然后自己注释了一个pom，问题就解决了

![29f11dff6e2bc7c0b9fba611e1a5d094](E:\qq聊天记录\Tencent Files\3301924694\nt_qq\nt_data\Pic\2024-12\Ori\29f11dff6e2bc7c0b9fba611e1a5d094.png)

### 	问题四：

​	Caused by: org.apache.flink.util.FlinkRuntimeException: Read split MySqlSnapshotSplit{tableId=demo.stu, splitId='demo.stu:0', splitKeyType=[`id` INT NOT NULL], splitStart=null, splitEnd=null, highWatermark=null} error due to org.apache.flink.util.FlinkRuntimeException: Cannot read the binlog filename and position via 'SHOW MASTER STATUS'. Make sure your server is correctly configured.

​	发现是binlog 的问题，突然想起来是刚配置的mysql，没有搞binlog，然后就去etc/my.conf文件里面更改配置就ok了

### 	问题五：

java.lang.IllegalStateException: No ClusterClientFactory found. If you were targeting a Yarn cluster, please make sure to export the HADOOP_CLASSPATH environment variable or have hadoop in your classpath. For more information refer to the "Deployment" section of the official Apache Flink documentation.        at org.apache.flink.client.deployment.DefaultClusterClientServiceLoader.getClusterClientFactory(DefaultClusterClientServiceLoader.java:83)        at org.apache.flink.client.deployment.application.cli.ApplicationClusterDeployer.run(ApplicationClusterDeployer.java:61)        at org.apache.flink.client.cli.CliFrontend.runApplication(CliFrontend.java:212)        at org.apache.flink.client.cli.CliFrontend.parseAndRun(CliFrontend.java:1098)        at org.apache.flink.client.cli.CliFrontend.lambda$mainInternal$9(CliFrontend.java:1189)        at org.apache.flink.runtime.security.contexts.NoOpSecurityContext.runSecured(NoOpSecurityContext.java:28)        at org.apache.flink.client.cli.CliFrontend.mainInternal(CliFrontend.java:1189)        at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:1157)



当时报这个错的时候，第一反应是新安装的flink没有配置环境变量，但是后面想了想，第一次部署的时候都成功，为什么这次报错了，然后就开始从头开始理思路，最后忘记执行一行代码：

##### 	export HADOOP_CLASSPATH=$(hadoop classpath)

### 	问题六：

​	![image-20241221090207466](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20241221090207466.png)

通过网上查找方法在flink/conf/flink-conf.yaml文件里面添加了一个classloader.resolve-order:parent-first，然后上网查了一下这个的意思，就明白了

![image-20241221090431340](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20241221090431340.png)

